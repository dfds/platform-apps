---
# Source: karpenter/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: karpenter
  namespace: karpenter
  labels:
    app.kubernetes.io/name: karpenter
    app.kubernetes.io/instance: karpenter
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  revisionHistoryLimit: 10
  strategy:
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: karpenter
      app.kubernetes.io/instance: karpenter
  template:
    metadata:
      labels:
        app.kubernetes.io/name: karpenter
        app.kubernetes.io/instance: karpenter
      annotations:
    spec:
      automountServiceAccountToken: true
      serviceAccountName: karpenter
      securityContext:
        fsGroup: 65532
        seccompProfile:
          type: RuntimeDefault
      priorityClassName: "system-cluster-critical"
      dnsPolicy: ClusterFirst
      schedulerName: "default-scheduler"
      containers:
        - name: controller
          securityContext:
            privileged: false
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 65532
            runAsGroup: 65532
            capabilities:
              drop:
                - ALL
          image: public.ecr.aws/karpenter/controller:1.9.0@sha256:30a506c64fbb1d8026cbfd9a1d662be3ab6e33a7999290a104085d78b49a69d7
          imagePullPolicy: IfNotPresent
          env:
            - name: KUBERNETES_MIN_VERSION
              value: "1.19.0-0"
            - name: KARPENTER_SERVICE
              value: karpenter
            - name: LOG_LEVEL
              value: "info"
            - name: LOG_OUTPUT_PATHS
              value: "stdout"
            - name: LOG_ERROR_OUTPUT_PATHS
              value: "stderr"
            - name: METRICS_PORT
              value: "8080"
            - name: HEALTH_PROBE_PORT
              value: "8081"
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CPU_REQUESTS
              valueFrom:
                resourceFieldRef:
                  containerName: controller
                  divisor: 1m
                  resource: requests.cpu
            - name: MEMORY_LIMIT
              valueFrom:
                resourceFieldRef:
                  containerName: controller
                  divisor: "0"
                  resource: limits.memory
            - name: FEATURE_GATES
              value: "ReservedCapacity=true,SpotToSpotConsolidation=true,NodeRepair=false,NodeOverlay=false,StaticCapacity=false"
            - name: BATCH_MAX_DURATION
              value: "10s"
            - name: BATCH_IDLE_DURATION
              value: "1s"
            - name: PREFERENCE_POLICY
              value: "Respect"
            - name: MIN_VALUES_POLICY
              value: "Strict"
            - name: CLUSTER_NAME
              value: "${flux_cluster_name}"
            - name: VM_MEMORY_OVERHEAD_PERCENT
              value: "0.075"
            - name: INTERRUPTION_QUEUE
              value: "Karpenter-${flux_cluster_name}"
            - name: RESERVED_ENIS
              value: "0"
            - name: IGNORE_DRA_REQUESTS
              value: "true"
          ports:
            - name: http-metrics
              containerPort: 8080
              protocol: TCP
            - name: http
              containerPort: 8081
              protocol: TCP
          livenessProbe:
            initialDelaySeconds: 30
            timeoutSeconds: 30
            httpGet:
              path: /healthz
              port: http
          readinessProbe:
            initialDelaySeconds: 5
            timeoutSeconds: 30
            httpGet:
              path: /readyz
              port: http
          resources:
            limits:
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 512Mi
      nodeSelector:
        karpenter.sh/controller: "true"
        kubernetes.io/os: linux
      # The template below patches the .Values.affinity to add a default label selector where not specificed
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: karpenter.sh/nodepool
                    operator: DoesNotExist
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app.kubernetes.io/instance: karpenter
                  app.kubernetes.io/name: karpenter
              topologyKey: kubernetes.io/hostname
      # The template below patches the .Values.topologySpreadConstraints to add a default label selector where not specificed
      topologySpreadConstraints:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/instance: karpenter
              app.kubernetes.io/name: karpenter
          maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: DoNotSchedule
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
