apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: grafana-k8s-monitoring
  namespace: flux-system
spec:
  releaseName: grafana-k8s-monitoring
  chart:
    spec:
      chart: k8s-monitoring
      version: 1.5.4
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
  interval: 1m0s
  install:
    remediation:
      retries: 3
  values:
    logs:
      enabled: true
      pod_logs:
        enabled: true
      cluster_events:
        enabled: true
      journal:
        enabled: true
        units: []
      extraConfig: |
        local.file_match "worker_nodes_logs" {
          path_targets = [{
            __address__ = "localhost",
            __path__    = "/var/log/**",
             __path_exclude__ = "/var/log/{pods,containers,journal}/**",
            instance = env("HOSTNAME"),
            job         = "integrations/kubernetes/worker-node",
          }]
        }

        loki.source.file "worker_nodes_logs" {
          targets    = local.file_match.worker_nodes_logs.targets
          forward_to = [loki.process.worker_nodes_logs.receiver]
        }

        loki.process "worker_nodes_logs" {
          forward_to = [
            loki.process.logs_service.receiver,
          ]
        }
    alloy-events: {}
    alloy-logs: {}
    metrics:
      enabled: true
      autoDiscover:
        enabled: false
      cost:
        enabled: ${open_cost_enabled}
      node-exporter:
        enabled: true
        metricsTuning:
          useDefaultAllowList: false
      serviceMonitors:
        enabled: true
        selector:
          |- # TODO: Delete this block when shutting down the old Prometheus
          match_expression {
            key = "release"
            operator = "NotIn"
            values = ["monitoring"]
          }
      kube-state-metrics:
        metricsTuning:
          useDefaultAllowList: false
      cadvisor:
        metricsTuning:
          useDefaultAllowList: false
    kube-state-metrics:
      enabled: true
      customLabels:
        jobLabel: kube-state-metrics
      resources:
        requests:
          cpu: 20m
          memory: 100Mi
      prometheus:
        monitor: # ServiceMonitor - TODO: Delete this block when shutting down the old Prometheus
          enabled: false
          # jobLabel: jobLabel
          # additionalLabels: {
          #   release: monitoring
          # }
    prometheus-node-exporter:
      enabled: true
      podLabels:
        jobLabel: node-exporter # Used for to set the label on the service for the ServiceMonitor
      resources:
        requests:
          cpu: 20m
          memory: 50Mi
      prometheus: #
        monitor: # TODO: Delete this block when shutting down the old Prometheus
          enabled: true
          jobLabel: jobLabel # Used for Prometheus to name the job. If jobLabel has not been set on the Service then default value will come from app.kubernetes.io/name
          additionalLabels: { release: monitoring }
    serverFiles:
      recording_rules.yml:
        groups:
          - interval: "3m"
            name: "kube-apiserver-availability.rules"
            rules:
              - expr: |
                  avg_over_time(code_verb:apiserver_request_total:increase1h[30d]) * 24 * 30
                record: "code_verb:apiserver_request_total:increase30d"
              - expr: |
                  sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"LIST|GET"})
                labels:
                  verb: "read"
                record: "code:apiserver_request_total:increase30d"
              - expr: |
                  sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
                labels:
                  verb: "write"
                record: "code:apiserver_request_total:increase30d"
              - expr: |
                  sum by (cluster, verb, scope) (increase(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver"}[1h]))
                record: "cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase1h"
              - expr: |
                  sum by (cluster, verb, scope) (avg_over_time(cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase1h[30d]) * 24 * 30)
                record: "cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d"
              - expr: |
                  sum by (cluster, verb, scope, le) (increase(apiserver_request_sli_duration_seconds_bucket[1h]))
                record: "cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase1h"
              - expr: |
                  sum by (cluster, verb, scope, le) (avg_over_time(cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase1h[30d]) * 24 * 30)
                record: "cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d"
              - expr: |
                  1 - (
                    (
                      # write too slow
                      sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
                      -
                      sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
                    ) +
                    (
                      # read too slow
                      sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~"LIST|GET"})
                      -
                      (
                        (
                          sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
                          or
                          vector(0)
                        )
                        +
                        sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
                        +
                        sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
                      )
                    ) +
                    # errors
                    sum by (cluster) (code:apiserver_request_total:increase30d{code=~"5.."} or vector(0))
                  )
                  /
                  sum by (cluster) (code:apiserver_request_total:increase30d)
                labels:
                  verb: "all"
                record: "apiserver_request:availability30d"
              - expr: |
                  1 - (
                    sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~"LIST|GET"})
                    -
                    (
                      # too slow
                      (
                        sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
                        or
                        vector(0)
                      )
                      +
                      sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
                      +
                      sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
                    )
                    +
                    # errors
                    sum by (cluster) (code:apiserver_request_total:increase30d{verb="read",code=~"5.."} or vector(0))
                  )
                  /
                  sum by (cluster) (code:apiserver_request_total:increase30d{verb="read"})
                labels:
                  verb: "read"
                record: "apiserver_request:availability30d"
              - expr: |
                  1 - (
                    (
                      # too slow
                      sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
                      -
                      sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
                    )
                    +
                    # errors
                    sum by (cluster) (code:apiserver_request_total:increase30d{verb="write",code=~"5.."} or vector(0))
                  )
                  /
                  sum by (cluster) (code:apiserver_request_total:increase30d{verb="write"})
                labels:
                  verb: "write"
                record: "apiserver_request:availability30d"
              - expr: |
                  sum by (cluster,code,resource) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET"}[5m]))
                labels:
                  verb: "read"
                record: "code_resource:apiserver_request_total:rate5m"
              - expr: |
                  sum by (cluster,code,resource) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
                labels:
                  verb: "write"
                record: "code_resource:apiserver_request_total:rate5m"
              - expr: |
                  sum by (cluster, code, verb) (increase(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"2.."}[1h]))
                record: "code_verb:apiserver_request_total:increase1h"
              - expr: |
                  sum by (cluster, code, verb) (increase(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"3.."}[1h]))
                record: "code_verb:apiserver_request_total:increase1h"
              - expr: |
                  sum by (cluster, code, verb) (increase(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"4.."}[1h]))
                record: "code_verb:apiserver_request_total:increase1h"
              - expr: |
                  sum by (cluster, code, verb) (increase(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
                record: "code_verb:apiserver_request_total:increase1h"
          - name: "kube-apiserver-burnrate.rules"
            rules:
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[1d]))
                      -
                      (
                        (
                          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[1d]))
                          or
                          vector(0)
                        )
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[1d]))
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[1d]))
                      )
                    )
                    +
                    # errors
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",code=~"5.."}[1d]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET"}[1d]))
                labels:
                  verb: "read"
                record: "apiserver_request:burnrate1d"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[1h]))
                      -
                      (
                        (
                          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[1h]))
                          or
                          vector(0)
                        )
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[1h]))
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[1h]))
                      )
                    )
                    +
                    # errors
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",code=~"5.."}[1h]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET"}[1h]))
                labels:
                  verb: "read"
                record: "apiserver_request:burnrate1h"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[2h]))
                      -
                      (
                        (
                          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[2h]))
                          or
                          vector(0)
                        )
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[2h]))
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[2h]))
                      )
                    )
                    +
                    # errors
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",code=~"5.."}[2h]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET"}[2h]))
                labels:
                  verb: "read"
                record: "apiserver_request:burnrate2h"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[30m]))
                      -
                      (
                        (
                          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[30m]))
                          or
                          vector(0)
                        )
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[30m]))
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[30m]))
                      )
                    )
                    +
                    # errors
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",code=~"5.."}[30m]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET"}[30m]))
                labels:
                  verb: "read"
                record: "apiserver_request:burnrate30m"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[3d]))
                      -
                      (
                        (
                          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[3d]))
                          or
                          vector(0)
                        )
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[3d]))
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[3d]))
                      )
                    )
                    +
                    # errors
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",code=~"5.."}[3d]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET"}[3d]))
                labels:
                  verb: "read"
                record: "apiserver_request:burnrate3d"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[5m]))
                      -
                      (
                        (
                          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[5m]))
                          or
                          vector(0)
                        )
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[5m]))
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[5m]))
                      )
                    )
                    +
                    # errors
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",code=~"5.."}[5m]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET"}[5m]))
                labels:
                  verb: "read"
                record: "apiserver_request:burnrate5m"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[6h]))
                      -
                      (
                        (
                          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[6h]))
                          or
                          vector(0)
                        )
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[6h]))
                        +
                        sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[6h]))
                      )
                    )
                    +
                    # errors
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",code=~"5.."}[6h]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET"}[6h]))
                labels:
                  verb: "read"
                record: "apiserver_request:burnrate6h"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[1d]))
                      -
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[1d]))
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1d]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1d]))
                labels:
                  verb: "write"
                record: "apiserver_request:burnrate1d"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[1h]))
                      -
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[1h]))
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1h]))
                labels:
                  verb: "write"
                record: "apiserver_request:burnrate1h"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[2h]))
                      -
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[2h]))
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[2h]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE"}[2h]))
                labels:
                  verb: "write"
                record: "apiserver_request:burnrate2h"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[30m]))
                      -
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[30m]))
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[30m]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE"}[30m]))
                labels:
                  verb: "write"
                record: "apiserver_request:burnrate30m"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[3d]))
                      -
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[3d]))
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[3d]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE"}[3d]))
                labels:
                  verb: "write"
                record: "apiserver_request:burnrate3d"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[5m]))
                      -
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[5m]))
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[5m]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
                labels:
                  verb: "write"
                record: "apiserver_request:burnrate5m"
              - expr: |
                  (
                    (
                      # too slow
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[6h]))
                      -
                      sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[6h]))
                    )
                    +
                    sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[6h]))
                  )
                  /
                  sum by (cluster) (rate(apiserver_request_total{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE"}[6h]))
                labels:
                  verb: "write"
                record: "apiserver_request:burnrate6h"
          - name: "kube-apiserver-histogram.rules"
            rules:
              - expr: |
                  histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[5m]))) > 0
                labels:
                  quantile: "0.99"
                  verb: "read"
                record: "cluster_quantile:apiserver_request_sli_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_sli_duration_seconds_bucket{job="integrations/kubernetes/kube-apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[5m]))) > 0
                labels:
                  quantile: "0.99"
                  verb: "write"
                record: "cluster_quantile:apiserver_request_sli_duration_seconds:histogram_quantile"
          - name: "k8s.rules.container_cpu_usage_seconds_total"
            rules:
              - expr: |
                  sum by (cluster, namespace, pod, container) (
                    irate(container_cpu_usage_seconds_total{job="integrations/kubernetes/cadvisor", image!=""}[5m])
                  ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (
                    1, max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
                  )
                record: "node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate"
          - name: "k8s.rules.container_memory_working_set_bytes"
            rules:
              - expr: |
                  container_memory_working_set_bytes{job="integrations/kubernetes/cadvisor", image!=""}
                  * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
                    max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
                  )
                record: "node_namespace_pod_container:container_memory_working_set_bytes"
          - name: "k8s.rules.container_memory_rss"
            rules:
              - expr: |
                  container_memory_rss{job="integrations/kubernetes/cadvisor", image!=""}
                  * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
                    max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
                  )
                record: "node_namespace_pod_container:container_memory_rss"
          - name: "k8s.rules.container_memory_cache"
            rules:
              - expr: |
                  container_memory_cache{job="integrations/kubernetes/cadvisor", image!=""}
                  * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
                    max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
                  )
                record: "node_namespace_pod_container:container_memory_cache"
          - name: "k8s.rules.container_memory_swap"
            rules:
              - expr: |
                  container_memory_swap{job="integrations/kubernetes/cadvisor", image!=""}
                  * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
                    max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
                  )
                record: "node_namespace_pod_container:container_memory_swap"
          - name: "k8s.rules.container_memory_requests"
            rules:
              - expr: |
                  kube_pod_container_resource_requests{resource="memory",job="integrations/kubernetes/kube-state-metrics"}  * on (namespace, pod, cluster)
                  group_left() max by (namespace, pod, cluster) (
                    (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
                  )
                record: "cluster:namespace:pod_memory:active:kube_pod_container_resource_requests"
              - expr: |
                  sum by (namespace, cluster) (
                      sum by (namespace, pod, cluster) (
                          max by (namespace, pod, container, cluster) (
                            kube_pod_container_resource_requests{resource="memory",job="integrations/kubernetes/kube-state-metrics"}
                          ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                            kube_pod_status_phase{phase=~"Pending|Running"} == 1
                          )
                      )
                  )
                record: "namespace_memory:kube_pod_container_resource_requests:sum"
          - name: "k8s.rules.container_cpu_requests"
            rules:
              - expr: |
                  kube_pod_container_resource_requests{resource="cpu",job="integrations/kubernetes/kube-state-metrics"}  * on (namespace, pod, cluster)
                  group_left() max by (namespace, pod, cluster) (
                    (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
                  )
                record: "cluster:namespace:pod_cpu:active:kube_pod_container_resource_requests"
              - expr: |
                  sum by (namespace, cluster) (
                      sum by (namespace, pod, cluster) (
                          max by (namespace, pod, container, cluster) (
                            kube_pod_container_resource_requests{resource="cpu",job="integrations/kubernetes/kube-state-metrics"}
                          ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                            kube_pod_status_phase{phase=~"Pending|Running"} == 1
                          )
                      )
                  )
                record: "namespace_cpu:kube_pod_container_resource_requests:sum"
          - name: "k8s.rules.container_memory_limits"
            rules:
              - expr: |
                  kube_pod_container_resource_limits{resource="memory",job="integrations/kubernetes/kube-state-metrics"}  * on (namespace, pod, cluster)
                  group_left() max by (namespace, pod, cluster) (
                    (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
                  )
                record: "cluster:namespace:pod_memory:active:kube_pod_container_resource_limits"
              - expr: |
                  sum by (namespace, cluster) (
                      sum by (namespace, pod, cluster) (
                          max by (namespace, pod, container, cluster) (
                            kube_pod_container_resource_limits{resource="memory",job="integrations/kubernetes/kube-state-metrics"}
                          ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                            kube_pod_status_phase{phase=~"Pending|Running"} == 1
                          )
                      )
                  )
                record: "namespace_memory:kube_pod_container_resource_limits:sum"
          - name: "k8s.rules.container_cpu_limits"
            rules:
              - expr: |
                  kube_pod_container_resource_limits{resource="cpu",job="integrations/kubernetes/kube-state-metrics"}  * on (namespace, pod, cluster)
                  group_left() max by (namespace, pod, cluster) (
                  (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
                  )
                record: "cluster:namespace:pod_cpu:active:kube_pod_container_resource_limits"
              - expr: |
                  sum by (namespace, cluster) (
                      sum by (namespace, pod, cluster) (
                          max by (namespace, pod, container, cluster) (
                            kube_pod_container_resource_limits{resource="cpu",job="integrations/kubernetes/kube-state-metrics"}
                          ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                            kube_pod_status_phase{phase=~"Pending|Running"} == 1
                          )
                      )
                  )
                record: "namespace_cpu:kube_pod_container_resource_limits:sum"
          - name: "k8s.rules.pod_owner"
            rules:
              - expr: |
                  max by (cluster, namespace, workload, pod) (
                    label_replace(
                      label_replace(
                        kube_pod_owner{job="integrations/kubernetes/kube-state-metrics", owner_kind="ReplicaSet"},
                        "replicaset", "$1", "owner_name", "(.*)"
                      ) * on(replicaset, namespace) group_left(owner_name) topk by(replicaset, namespace) (
                        1, max by (replicaset, namespace, owner_name) (
                          kube_replicaset_owner{job="integrations/kubernetes/kube-state-metrics"}
                        )
                      ),
                      "workload", "$1", "owner_name", "(.*)"
                    )
                  )
                labels:
                  workload_type: "deployment"
                record: "namespace_workload_pod:kube_pod_owner:relabel"
              - expr: |
                  max by (cluster, namespace, workload, pod) (
                    label_replace(
                      kube_pod_owner{job="integrations/kubernetes/kube-state-metrics", owner_kind="DaemonSet"},
                      "workload", "$1", "owner_name", "(.*)"
                    )
                  )
                labels:
                  workload_type: "daemonset"
                record: "namespace_workload_pod:kube_pod_owner:relabel"
              - expr: |
                  max by (cluster, namespace, workload, pod) (
                    label_replace(
                      kube_pod_owner{job="integrations/kubernetes/kube-state-metrics", owner_kind="StatefulSet"},
                      "workload", "$1", "owner_name", "(.*)"
                    )
                  )
                labels:
                  workload_type: "statefulset"
                record: "namespace_workload_pod:kube_pod_owner:relabel"
              - expr: |
                  max by (cluster, namespace, workload, pod) (
                    label_replace(
                      kube_pod_owner{job="integrations/kubernetes/kube-state-metrics", owner_kind="Job"},
                      "workload", "$1", "owner_name", "(.*)"
                    )
                  )
                labels:
                  workload_type: "job"
                record: "namespace_workload_pod:kube_pod_owner:relabel"
          - name: "kube-scheduler.rules"
            rules:
              - expr: |
                  histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="integrations/kubernetes/kube-scheduler"}[5m])) without(instance, pod))
                labels:
                  quantile: "0.99"
                record: "cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="integrations/kubernetes/kube-scheduler"}[5m])) without(instance, pod))
                labels:
                  quantile: "0.99"
                record: "cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.99, sum(rate(scheduler_binding_duration_seconds_bucket{job="integrations/kubernetes/kube-scheduler"}[5m])) without(instance, pod))
                labels:
                  quantile: "0.99"
                record: "cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="integrations/kubernetes/kube-scheduler"}[5m])) without(instance, pod))
                labels:
                  quantile: "0.9"
                record: "cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="integrations/kubernetes/kube-scheduler"}[5m])) without(instance, pod))
                labels:
                  quantile: "0.9"
                record: "cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.9, sum(rate(scheduler_binding_duration_seconds_bucket{job="integrations/kubernetes/kube-scheduler"}[5m])) without(instance, pod))
                labels:
                  quantile: "0.9"
                record: "cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="integrations/kubernetes/kube-scheduler"}[5m])) without(instance, pod))
                labels:
                  quantile: "0.5"
                record: "cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="integrations/kubernetes/kube-scheduler"}[5m])) without(instance, pod))
                labels:
                  quantile: "0.5"
                record: "cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.5, sum(rate(scheduler_binding_duration_seconds_bucket{job="integrations/kubernetes/kube-scheduler"}[5m])) without(instance, pod))
                labels:
                  quantile: "0.5"
                record: "cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile"
          - name: "node.rules"
            rules:
              - expr: |
                  topk by(cluster, namespace, pod) (1,
                    max by (cluster, node, namespace, pod) (
                      label_replace(kube_pod_info{job="integrations/kubernetes/kube-state-metrics",node!=""}, "pod", "$1", "pod", "(.*)")
                  ))
                record: "node_namespace_pod:kube_pod_info:"
              - expr: |
                  count by (cluster, node) (
                    node_cpu_seconds_total{mode="idle",job="node-exporter"}
                    * on (cluster, namespace, pod) group_left(node)
                    topk by(cluster, namespace, pod) (1, node_namespace_pod:kube_pod_info:)
                  )
                record: "node:node_num_cpu:sum"
              - expr: |
                  sum(
                    node_memory_MemAvailable_bytes{job="node-exporter"} or
                    (
                      node_memory_Buffers_bytes{job="node-exporter"} +
                      node_memory_Cached_bytes{job="node-exporter"} +
                      node_memory_MemFree_bytes{job="node-exporter"} +
                      node_memory_Slab_bytes{job="node-exporter"}
                    )
                  ) by (cluster)
                record: ":node_memory_MemAvailable_bytes:sum"
              - expr: |
                  avg by (cluster, node) (
                    sum without (mode) (
                      rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal",job="node-exporter"}[5m])
                    )
                  )
                record: "node:node_cpu_utilization:ratio_rate5m"
              - expr: |
                  avg by (cluster) (
                    node:node_cpu_utilization:ratio_rate5m
                  )
                record: "cluster:node_cpu:ratio_rate5m"
          - name: "kubelet.rules"
            rules:
              - expr: |
                  histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="integrations/kubernetes/kubelet"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="integrations/kubernetes/kubelet"})
                labels:
                  quantile: "0.99"
                record: "node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.9, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="integrations/kubernetes/kubelet"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="integrations/kubernetes/kubelet"})
                labels:
                  quantile: "0.9"
                record: "node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile"
              - expr: |
                  histogram_quantile(0.5, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="integrations/kubernetes/kubelet"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="integrations/kubernetes/kubelet"})
                labels:
                  quantile: "0.5"
                record: "node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile"

    prometheus-operator-crds:
      # Set this to true when removing the old Prometheus stack
      enabled: false
    extraObjects:
      - apiVersion: monitoring.coreos.com/v1
        kind: ServiceMonitor
        metadata:
          labels:
            app: prometheus-service-metrics-scraper
          name: prometheus-service-metrics-scraper
        spec:
          endpoints:
            - path: /metrics
              port: metrics
              scrapeTimeout: 30s
            - path: /metrics
              port: admin
            - path: /metrics
              port: http
          namespaceSelector:
            any: true
          selector:
            matchLabels:
              scrape-service-metrics: "true"

      # Delete below service monitors when shutting down the old Prometheus
      - apiVersion: monitoring.coreos.com/v1
        kind: ServiceMonitor
        metadata:
          name: kube-prometheus-stack-coredns
          labels:
            app: kube-prometheus-stack-coredns
            app.kubernetes.io/instance: kube-prometheus-stack
            release: monitoring
        spec:
          jobLabel: jobLabel
          selector:
            matchLabels:
              app: kube-prometheus-stack-coredns
              release: monitoring
          namespaceSelector:
            matchNames:
              - kube-system
          endpoints:
            - port: http-metrics
              bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
      - apiVersion: v1
        kind: Service
        metadata:
          name: kube-prometheus-stack-coredns
          labels:
            app: kube-prometheus-stack-coredns
            jobLabel: coredns
            app.kubernetes.io/instance: kube-prometheus-stack
            release: monitoring
          namespace: kube-system
        spec:
          clusterIP: None
          ports:
            - name: http-metrics
              port: 9153
              protocol: TCP
              targetPort: 9153
          selector:
            k8s-app: kube-dns
      ###################################
      - apiVersion: monitoring.coreos.com/v1
        kind: ServiceMonitor
        metadata:
          labels:
            app: kube-prometheus-stack-kubelet
            release: monitoring
          name: monitoring-kube-prometheus-kubelet
        spec:
          attachMetadata:
            node: false
          endpoints:
            - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
              honorLabels: true
              honorTimestamps: true
              port: https-metrics
              relabelings:
                - action: replace
                  sourceLabels:
                    - __metrics_path__
                  targetLabel: metrics_path
              scheme: https
              tlsConfig:
                caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecureSkipVerify: true
            - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
              honorLabels: true
              honorTimestamps: true
              metricRelabelings:
                - action: labeldrop
                  regex: id
                - action: labeldrop
                  regex: name
              path: /metrics/cadvisor
              port: https-metrics
              relabelings:
                - action: replace
                  sourceLabels:
                    - __metrics_path__
                  targetLabel: metrics_path
              scheme: https
              tlsConfig:
                caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecureSkipVerify: true
            - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
              honorLabels: true
              honorTimestamps: true
              path: /metrics/probes
              port: https-metrics
              relabelings:
                - action: replace
                  sourceLabels:
                    - __metrics_path__
                  targetLabel: metrics_path
              scheme: https
              tlsConfig:
                caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecureSkipVerify: true
          jobLabel: k8s-app
          namespaceSelector:
            matchNames:
              - kube-system
          selector:
            matchLabels:
              app.kubernetes.io/name: kubelet
              k8s-app: kubelet
      ##########################
      - apiVersion: monitoring.coreos.com/v1
        kind: ServiceMonitor
        metadata:
          name: kube-prometheus-stack-apiserver
          labels:
            app: kube-prometheus-stack-apiserver
            app.kubernetes.io/instance: kube-prometheus-stack
            release: monitoring
        spec:
          endpoints:
            - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
              port: https
              scheme: https
              metricRelabelings:
                - action: drop
                  regex: apiserver_request_duration_seconds_bucket;(0.15|0.2|0.3|0.35|0.4|0.45|0.6|0.7|0.8|0.9|1.25|1.5|1.75|2|3|3.5|4|4.5|6|7|8|9|15|25|40|50)
                  sourceLabels:
                    - __name__
                    - le
              tlsConfig:
                caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                serverName: kubernetes
                insecureSkipVerify: false
          jobLabel: component
          namespaceSelector:
            matchNames:
              - default
          selector:
            matchLabels:
              component: apiserver
              provider: kubernetes
        ####
